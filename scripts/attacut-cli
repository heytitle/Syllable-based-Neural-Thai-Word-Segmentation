#!/usr/bin/env python

"""AttaCut: Fast and Reasonably Accurate Word Tokenizer for Thai

Usage:
  attacut-cli <src> [--dest=<dest>] [--model=<model>] [--num-cores=<num-cores>] [--batch-size=<batch-size>] [--gpu]
  attacut-cli [-v | --version]
  attacut-cli [-h | --help]

Arguments:
  <src>             Path to input text file to be tokenized

Options:
  -h --help         Show this screen.
  --model=<model>   Model to be used [default: attacut-sc].
  --dest=<dest>     If not specified, it'll be <src>-tokenized-by-<model>.txt
  -v --version      Show version
  --num-cores=<num-cores>  Use multiple-core processing [default: 0]
  --batch-size=<batch-size>  Batch size [default: 20]
"""

from docopt import docopt
from attacut import command, __version__

if __name__ == "__main__":
    arguments = docopt(__doc__, version=f"AttaCut: version {__version__}")

    command.main(
        arguments["<src>"],
        arguments["--model"],
        int(arguments["--num-cores"]),
        int(arguments["--batch-size"]),
        dest=arguments["--dest"],
        device="cuda" if arguments["--gpu"] else "cpu"
    )